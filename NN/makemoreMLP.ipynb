{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests as rqst\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build index look up table\n",
    "stoi = {char: i + 1 for i, char in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i : char for char, i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ----> e\n",
      "..e ----> m\n",
      ".em ----> m\n",
      "emm ----> a\n",
      "mma ----> .\n",
      "olivia\n",
      "... ----> o\n",
      "..o ----> l\n",
      ".ol ----> i\n",
      "oli ----> v\n",
      "liv ----> i\n",
      "ivi ----> a\n",
      "via ----> .\n",
      "ava\n",
      "... ----> a\n",
      "..a ----> v\n",
      ".av ----> a\n",
      "ava ----> .\n",
      "isabella\n",
      "... ----> i\n",
      "..i ----> s\n",
      ".is ----> a\n",
      "isa ----> b\n",
      "sab ----> e\n",
      "abe ----> l\n",
      "bel ----> l\n",
      "ell ----> a\n",
      "lla ----> .\n",
      "sophia\n",
      "... ----> s\n",
      "..s ----> o\n",
      ".so ----> p\n",
      "sop ----> h\n",
      "oph ----> i\n",
      "phi ----> a\n",
      "hia ----> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "X, Y = [], []\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    context = [0]*block_size\n",
    "    for char in word + \".\":\n",
    "        ix = stoi[char]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples of X: tensor([[0, 0, 0],\n",
      "        [0, 0, 5]])\n",
      " samples of Y: tensor([ 5, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\" samples of X: {X[:2]}\")\n",
    "print(f\" samples of Y: {Y[:2]}\")\n",
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding into smaller dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4507,  0.5883])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "C = torch.randn((27, 2)) # look up table\n",
    "# embedding one interger\n",
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4507,  0.5883])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using one-hot encoding\n",
    "\n",
    "emb_five = F.one_hot(torch.tensor(5), num_classes=27)\n",
    "emb_five.dtype # (torch.int64) which is a long\n",
    "emb_five.float() @ C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion\n",
    "\n",
    "---\n",
    "\n",
    "The result is the same as the just indexing because matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.4507,  0.5883]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.4507,  0.5883],\n",
       "         [ 0.8921,  0.6443]],\n",
       "\n",
       "        [[-0.4507,  0.5883],\n",
       "         [ 0.8921,  0.6443],\n",
       "         [ 0.8921,  0.6443]],\n",
       "\n",
       "        [[ 0.8921,  0.6443],\n",
       "         [ 0.8921,  0.6443],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.4456, -1.0036]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.4456, -1.0036],\n",
       "         [ 0.2209,  0.8026]],\n",
       "\n",
       "        [[-0.4456, -1.0036],\n",
       "         [ 0.2209,  0.8026],\n",
       "         [ 1.8280, -0.3603]],\n",
       "\n",
       "        [[ 0.2209,  0.8026],\n",
       "         [ 1.8280, -0.3603],\n",
       "         [ 0.6267, -0.1460]],\n",
       "\n",
       "        [[ 1.8280, -0.3603],\n",
       "         [ 0.6267, -0.1460],\n",
       "         [ 1.8280, -0.3603]],\n",
       "\n",
       "        [[ 0.6267, -0.1460],\n",
       "         [ 1.8280, -0.3603],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [ 0.4130, -1.7827],\n",
       "         [ 0.6267, -0.1460]],\n",
       "\n",
       "        [[ 0.4130, -1.7827],\n",
       "         [ 0.6267, -0.1460],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [ 1.8280, -0.3603]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [ 1.8280, -0.3603],\n",
       "         [ 0.5337, -0.5609]],\n",
       "\n",
       "        [[ 1.8280, -0.3603],\n",
       "         [ 0.5337, -0.5609],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[ 0.5337, -0.5609],\n",
       "         [ 0.4130, -1.7827],\n",
       "         [-0.1140, -1.3774]],\n",
       "\n",
       "        [[ 0.4130, -1.7827],\n",
       "         [-0.1140, -1.3774],\n",
       "         [-0.4507,  0.5883]],\n",
       "\n",
       "        [[-0.1140, -1.3774],\n",
       "         [-0.4507,  0.5883],\n",
       "         [ 0.2209,  0.8026]],\n",
       "\n",
       "        [[-0.4507,  0.5883],\n",
       "         [ 0.2209,  0.8026],\n",
       "         [ 0.2209,  0.8026]],\n",
       "\n",
       "        [[ 0.2209,  0.8026],\n",
       "         [ 0.2209,  0.8026],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [ 0.5337, -0.5609]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [ 0.5337, -0.5609],\n",
       "         [-0.4456, -1.0036]],\n",
       "\n",
       "        [[ 0.5337, -0.5609],\n",
       "         [-0.4456, -1.0036],\n",
       "         [ 0.9431, -0.5273]],\n",
       "\n",
       "        [[-0.4456, -1.0036],\n",
       "         [ 0.9431, -0.5273],\n",
       "         [ 0.5975,  1.1457]],\n",
       "\n",
       "        [[ 0.9431, -0.5273],\n",
       "         [ 0.5975,  1.1457],\n",
       "         [ 1.8280, -0.3603]],\n",
       "\n",
       "        [[ 0.5975,  1.1457],\n",
       "         [ 1.8280, -0.3603],\n",
       "         [ 0.4130, -1.7827]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## torch indexing is very powerful. you can actually use lists or tensors as indices and it should get everything there. my God, R poisoned everything!!\n",
    "print(C[X].shape)\n",
    "C[X] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[13,2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
