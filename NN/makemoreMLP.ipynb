{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests as rqst\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build index look up table\n",
    "stoi = {char: i + 1 for i, char in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i : char for char, i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ----> e\n",
      "..e ----> m\n",
      ".em ----> m\n",
      "emm ----> a\n",
      "mma ----> .\n",
      "olivia\n",
      "... ----> o\n",
      "..o ----> l\n",
      ".ol ----> i\n",
      "oli ----> v\n",
      "liv ----> i\n",
      "ivi ----> a\n",
      "via ----> .\n",
      "ava\n",
      "... ----> a\n",
      "..a ----> v\n",
      ".av ----> a\n",
      "ava ----> .\n",
      "isabella\n",
      "... ----> i\n",
      "..i ----> s\n",
      ".is ----> a\n",
      "isa ----> b\n",
      "sab ----> e\n",
      "abe ----> l\n",
      "bel ----> l\n",
      "ell ----> a\n",
      "lla ----> .\n",
      "sophia\n",
      "... ----> s\n",
      "..s ----> o\n",
      ".so ----> p\n",
      "sop ----> h\n",
      "oph ----> i\n",
      "phi ----> a\n",
      "hia ----> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "X, Y = [], []\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    context = [0]*block_size\n",
    "    for char in word + \".\":\n",
    "        ix = stoi[char]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples of X: tensor([[0, 0, 0],\n",
      "        [0, 0, 5]])\n",
      " samples of Y: tensor([ 5, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\" samples of X: {X[:2]}\")\n",
    "print(f\" samples of Y: {Y[:2]}\")\n",
    "X.shape, X.dtype, Y.shape, Y.dtype # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding into smaller dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2375,  0.1140])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "C = torch.randn((27, 2)) # look up table\n",
    "# embedding one interger\n",
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2375,  0.1140])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using one-hot encoding\n",
    "\n",
    "emb_five = F.one_hot(torch.tensor(5), num_classes=27)\n",
    "emb_five.dtype # (torch.int64) which is a long\n",
    "emb_five.float() @ C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion\n",
    "\n",
    "---\n",
    "\n",
    "The result is the same as the just indexing because matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [-1.2375,  0.1140]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-1.2375,  0.1140],\n",
       "         [-3.2033, -0.3469]],\n",
       "\n",
       "        [[-1.2375,  0.1140],\n",
       "         [-3.2033, -0.3469],\n",
       "         [-3.2033, -0.3469]],\n",
       "\n",
       "        [[-3.2033, -0.3469],\n",
       "         [-3.2033, -0.3469],\n",
       "         [-0.1400,  0.5173]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [-1.9791, -0.4745]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-1.9791, -0.4745],\n",
       "         [-0.6213,  2.7754]],\n",
       "\n",
       "        [[-1.9791, -0.4745],\n",
       "         [-0.6213,  2.7754],\n",
       "         [-0.3472, -0.4749]],\n",
       "\n",
       "        [[-0.6213,  2.7754],\n",
       "         [-0.3472, -0.4749],\n",
       "         [-0.1199,  0.7997]],\n",
       "\n",
       "        [[-0.3472, -0.4749],\n",
       "         [-0.1199,  0.7997],\n",
       "         [-0.3472, -0.4749]],\n",
       "\n",
       "        [[-0.1199,  0.7997],\n",
       "         [-0.3472, -0.4749],\n",
       "         [-0.1400,  0.5173]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [-0.1400,  0.5173]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.1400,  0.5173],\n",
       "         [-0.1199,  0.7997]],\n",
       "\n",
       "        [[-0.1400,  0.5173],\n",
       "         [-0.1199,  0.7997],\n",
       "         [-0.1400,  0.5173]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [-0.3472, -0.4749]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3472, -0.4749],\n",
       "         [ 1.3498, -0.0150]],\n",
       "\n",
       "        [[-0.3472, -0.4749],\n",
       "         [ 1.3498, -0.0150],\n",
       "         [-0.1400,  0.5173]],\n",
       "\n",
       "        [[ 1.3498, -0.0150],\n",
       "         [-0.1400,  0.5173],\n",
       "         [-0.0414, -1.1877]],\n",
       "\n",
       "        [[-0.1400,  0.5173],\n",
       "         [-0.0414, -1.1877],\n",
       "         [-1.2375,  0.1140]],\n",
       "\n",
       "        [[-0.0414, -1.1877],\n",
       "         [-1.2375,  0.1140],\n",
       "         [-0.6213,  2.7754]],\n",
       "\n",
       "        [[-1.2375,  0.1140],\n",
       "         [-0.6213,  2.7754],\n",
       "         [-0.6213,  2.7754]],\n",
       "\n",
       "        [[-0.6213,  2.7754],\n",
       "         [-0.6213,  2.7754],\n",
       "         [-0.1400,  0.5173]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [-0.3491, -0.6884],\n",
       "         [ 1.3498, -0.0150]],\n",
       "\n",
       "        [[-0.3491, -0.6884],\n",
       "         [ 1.3498, -0.0150],\n",
       "         [-1.9791, -0.4745]],\n",
       "\n",
       "        [[ 1.3498, -0.0150],\n",
       "         [-1.9791, -0.4745],\n",
       "         [-1.1382,  1.0663]],\n",
       "\n",
       "        [[-1.9791, -0.4745],\n",
       "         [-1.1382,  1.0663],\n",
       "         [-0.2293,  1.6071]],\n",
       "\n",
       "        [[-1.1382,  1.0663],\n",
       "         [-0.2293,  1.6071],\n",
       "         [-0.3472, -0.4749]],\n",
       "\n",
       "        [[-0.2293,  1.6071],\n",
       "         [-0.3472, -0.4749],\n",
       "         [-0.1400,  0.5173]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## torch indexing is very powerful. you can actually use lists or tensors as indices and it should get everything there. my God, R poisoned everything!!\n",
    "print(C[X].shape)\n",
    "emb = C[X]\n",
    "emb\n",
    "\n",
    "# this first list of list of list from the output represents from [0,0,0] for the first word: tensor([[[-0.2244, -2.2367],\n",
    "                                                                                                #[-0.2244, -2.2367],\n",
    "                                                                                                #[-0.2244, -2.2367]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3491, -0.6884],\n",
       "        [-0.3491, -0.6884],\n",
       "        [-0.3491, -0.6884]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X[0,0]) # type: ignore\n",
    "emb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.6626,  1.1382,  0.4414, -0.9961,  1.1724,  0.5139, -1.6073,  1.8050,\n",
       "        -0.7537,  0.3273, -1.3357,  1.4887,  0.4429, -0.4079,  1.2124, -0.7905,\n",
       "        -0.4999, -2.0080, -0.0712,  0.2288,  1.0121,  0.4022,  1.5563, -0.1665,\n",
       "         0.9227, -0.6304,  1.6090,  0.1770, -0.4674, -0.3271,  0.5235,  0.2529,\n",
       "         0.2663, -0.0508, -1.1151, -2.8558, -0.1888, -0.1678,  0.6549, -2.0097,\n",
       "         0.5369,  2.3578, -0.5600, -0.0773,  1.2689, -0.0460, -0.7059, -1.7549,\n",
       "        -2.1820, -1.3235, -1.9751, -0.4566, -0.9876, -0.3990,  1.2888, -0.7201,\n",
       "        -1.4283, -0.3556, -0.4116, -0.8644,  1.5038,  1.0587, -2.0885,  0.2623,\n",
       "        -0.2587, -0.4344,  1.1998,  0.6714,  0.0307, -0.7529,  1.4484, -1.5830,\n",
       "         0.7927, -0.3378,  0.0556, -0.3708, -0.1410, -1.3243, -0.0030, -0.8132,\n",
       "        -0.6422,  1.1896,  2.7139, -0.7196,  0.8066, -1.3035, -1.4769, -1.2684,\n",
       "         0.0874, -2.0976, -1.4507,  1.1109,  1.8382, -0.2526, -0.0689, -0.6452,\n",
       "        -0.2320, -1.1050,  1.9809,  1.0217])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = torch.randn(6,100) # 6 because we have 2-D embeddings for each char and there is 3 for each context. the 100 represent the number of neurons we have in the layer\n",
    "b = torch.randn(100) # why not b = torch.randn(1, 100)?\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-1.2375,  0.1140],\n",
      "        [-3.2033, -0.3469],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-1.9791, -0.4745],\n",
      "        [-0.6213,  2.7754],\n",
      "        [-0.3472, -0.4749],\n",
      "        [-0.1199,  0.7997],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.1400,  0.5173],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3472, -0.4749],\n",
      "        [ 1.3498, -0.0150],\n",
      "        [-0.1400,  0.5173],\n",
      "        [-0.0414, -1.1877],\n",
      "        [-1.2375,  0.1140],\n",
      "        [-0.6213,  2.7754],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [-0.3491, -0.6884],\n",
      "        [ 1.3498, -0.0150],\n",
      "        [-1.9791, -0.4745],\n",
      "        [-1.1382,  1.0663],\n",
      "        [-0.2293,  1.6071]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how are we going to do the matrix multiplication between a (32,3,2) and (3,2) tensor?\n",
    "\n",
    "# first option, use concat to concat the input\n",
    "print(emb[:,0,:])\n",
    "\n",
    "emb[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
