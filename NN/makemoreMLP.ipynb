{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests as rqst\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build index look up table\n",
    "stoi = {char: i + 1 for i, char in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i : char for char, i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ----> e\n",
      "..e ----> m\n",
      ".em ----> m\n",
      "emm ----> a\n",
      "mma ----> .\n",
      "olivia\n",
      "... ----> o\n",
      "..o ----> l\n",
      ".ol ----> i\n",
      "oli ----> v\n",
      "liv ----> i\n",
      "ivi ----> a\n",
      "via ----> .\n",
      "ava\n",
      "... ----> a\n",
      "..a ----> v\n",
      ".av ----> a\n",
      "ava ----> .\n",
      "isabella\n",
      "... ----> i\n",
      "..i ----> s\n",
      ".is ----> a\n",
      "isa ----> b\n",
      "sab ----> e\n",
      "abe ----> l\n",
      "bel ----> l\n",
      "ell ----> a\n",
      "lla ----> .\n",
      "sophia\n",
      "... ----> s\n",
      "..s ----> o\n",
      ".so ----> p\n",
      "sop ----> h\n",
      "oph ----> i\n",
      "phi ----> a\n",
      "hia ----> .\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "X, Y = [], []\n",
    "for word in words[:5]:\n",
    "    print(word)\n",
    "    context = [0]*block_size\n",
    "    for char in word + \".\":\n",
    "        ix = stoi[char]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " samples of X: tensor([[0, 0, 0],\n",
      "        [0, 0, 5]])\n",
      " samples of Y: tensor([ 5, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\" samples of X: {X[:2]}\")\n",
    "print(f\" samples of Y: {Y[:2]}\")\n",
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding into smaller dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4507,  0.5883])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "C = torch.randn((27, 2)) # look up table\n",
    "# embedding one interger\n",
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4507,  0.5883])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using one-hot encoding\n",
    "\n",
    "emb_five = F.one_hot(torch.tensor(5), num_classes=27)\n",
    "emb_five.dtype # (torch.int64) which is a long\n",
    "emb_five.float() @ C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion\n",
    "\n",
    "---\n",
    "\n",
    "The result is the same as the just indexing because matrix multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.4507,  0.5883]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.4507,  0.5883],\n",
       "         [ 0.8921,  0.6443]],\n",
       "\n",
       "        [[-0.4507,  0.5883],\n",
       "         [ 0.8921,  0.6443],\n",
       "         [ 0.8921,  0.6443]],\n",
       "\n",
       "        [[ 0.8921,  0.6443],\n",
       "         [ 0.8921,  0.6443],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.4456, -1.0036]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.4456, -1.0036],\n",
       "         [ 0.2209,  0.8026]],\n",
       "\n",
       "        [[-0.4456, -1.0036],\n",
       "         [ 0.2209,  0.8026],\n",
       "         [ 1.8280, -0.3603]],\n",
       "\n",
       "        [[ 0.2209,  0.8026],\n",
       "         [ 1.8280, -0.3603],\n",
       "         [ 0.6267, -0.1460]],\n",
       "\n",
       "        [[ 1.8280, -0.3603],\n",
       "         [ 0.6267, -0.1460],\n",
       "         [ 1.8280, -0.3603]],\n",
       "\n",
       "        [[ 0.6267, -0.1460],\n",
       "         [ 1.8280, -0.3603],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [ 0.4130, -1.7827],\n",
       "         [ 0.6267, -0.1460]],\n",
       "\n",
       "        [[ 0.4130, -1.7827],\n",
       "         [ 0.6267, -0.1460],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [ 1.8280, -0.3603]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [ 1.8280, -0.3603],\n",
       "         [ 0.5337, -0.5609]],\n",
       "\n",
       "        [[ 1.8280, -0.3603],\n",
       "         [ 0.5337, -0.5609],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[ 0.5337, -0.5609],\n",
       "         [ 0.4130, -1.7827],\n",
       "         [-0.1140, -1.3774]],\n",
       "\n",
       "        [[ 0.4130, -1.7827],\n",
       "         [-0.1140, -1.3774],\n",
       "         [-0.4507,  0.5883]],\n",
       "\n",
       "        [[-0.1140, -1.3774],\n",
       "         [-0.4507,  0.5883],\n",
       "         [ 0.2209,  0.8026]],\n",
       "\n",
       "        [[-0.4507,  0.5883],\n",
       "         [ 0.2209,  0.8026],\n",
       "         [ 0.2209,  0.8026]],\n",
       "\n",
       "        [[ 0.2209,  0.8026],\n",
       "         [ 0.2209,  0.8026],\n",
       "         [ 0.4130, -1.7827]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [-0.2244, -2.2367],\n",
       "         [ 0.5337, -0.5609]],\n",
       "\n",
       "        [[-0.2244, -2.2367],\n",
       "         [ 0.5337, -0.5609],\n",
       "         [-0.4456, -1.0036]],\n",
       "\n",
       "        [[ 0.5337, -0.5609],\n",
       "         [-0.4456, -1.0036],\n",
       "         [ 0.9431, -0.5273]],\n",
       "\n",
       "        [[-0.4456, -1.0036],\n",
       "         [ 0.9431, -0.5273],\n",
       "         [ 0.5975,  1.1457]],\n",
       "\n",
       "        [[ 0.9431, -0.5273],\n",
       "         [ 0.5975,  1.1457],\n",
       "         [ 1.8280, -0.3603]],\n",
       "\n",
       "        [[ 0.5975,  1.1457],\n",
       "         [ 1.8280, -0.3603],\n",
       "         [ 0.4130, -1.7827]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## torch indexing is very powerful. you can actually use lists or tensors as indices and it should get everything there. my God, R poisoned everything!!\n",
    "print(C[X].shape)\n",
    "emb = C[X]\n",
    "emb\n",
    "\n",
    "# this first list of list of list from the output represents from [0,0,0] for the first word: tensor([[[-0.2244, -2.2367],\n",
    "                                                                                                #[-0.2244, -2.2367],\n",
    "                                                                                                #[-0.2244, -2.2367]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2244, -2.2367],\n",
       "        [-0.2244, -2.2367],\n",
       "        [-0.2244, -2.2367]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X[0,0])\n",
    "emb[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5379,  0.1178, -0.3910,  1.0925,  1.7204, -0.5543,  0.4283,  0.1344,\n",
       "         1.2667,  0.4174, -1.1313,  1.3653,  0.0847, -0.1801,  0.4214,  2.0202,\n",
       "        -0.1225,  0.2508,  0.8966,  0.4803,  0.3166,  1.1976, -0.2046,  0.8643,\n",
       "        -0.2389, -0.9995,  0.9044,  0.0677,  0.2839,  0.0499,  1.0757,  0.2065,\n",
       "        -2.5141,  0.1581,  0.1207, -0.8716, -0.4637,  0.2155,  0.2319, -0.2770,\n",
       "         0.1123, -0.0778,  0.8147, -1.5275,  1.2225,  0.3626,  0.7838, -0.5317,\n",
       "         1.2423, -0.3128,  0.1466, -0.2406,  0.3843, -2.9398, -0.5915, -0.0422,\n",
       "         1.2915,  1.2169, -0.8571, -1.8310, -1.2037, -0.3812,  1.3656,  0.8972,\n",
       "         0.2441, -0.4856,  0.4529,  0.8289,  0.7229,  0.6773, -0.7388,  1.2543,\n",
       "         0.4733,  1.0236, -0.0628, -1.5502,  0.6762,  0.6232, -2.0483, -1.5754,\n",
       "        -0.2245, -0.2473, -0.5865,  0.2130, -1.8506, -1.8898, -1.0634, -1.1460,\n",
       "        -0.6928,  0.3696,  0.6713, -0.0932, -0.8044, -0.8232, -1.6594, -0.8658,\n",
       "         0.1671,  0.7748,  0.5460, -0.7551])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = torch.randn(6,100) # 6 because we have 2-D embeddings for each char and there is 3 for each context. the 100 represent the number of neurons we have in the layer\n",
    "b = torch.randn(100) # why not b = torch.randn(1, 100)?\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.4507,  0.5883],\n",
      "        [ 0.8921,  0.6443],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.4456, -1.0036],\n",
      "        [ 0.2209,  0.8026],\n",
      "        [ 1.8280, -0.3603],\n",
      "        [ 0.6267, -0.1460],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [ 0.4130, -1.7827],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [ 1.8280, -0.3603],\n",
      "        [ 0.5337, -0.5609],\n",
      "        [ 0.4130, -1.7827],\n",
      "        [-0.1140, -1.3774],\n",
      "        [-0.4507,  0.5883],\n",
      "        [ 0.2209,  0.8026],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [-0.2244, -2.2367],\n",
      "        [ 0.5337, -0.5609],\n",
      "        [-0.4456, -1.0036],\n",
      "        [ 0.9431, -0.5273],\n",
      "        [ 0.5975,  1.1457]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how are we going to do the matrix multiplication between a (32,3,2) and (3,2) tensor?\n",
    "\n",
    "# first option, use concat to concat the input\n",
    "print(emb[:,0,:])\n",
    "\n",
    "emb[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
